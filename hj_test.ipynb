{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib as mpl\n",
    "# # import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 48)\n",
      "(1000, 48)\n",
      "(700, 48)\n"
     ]
    }
   ],
   "source": [
    "data_g=pd.read_excel('C:/Users/user/Desktop/psl/fault_feature_jirak.xls')\n",
    "data_l=pd.read_excel('C:/Users/user/Desktop/psl/fault_feature 2L_1000.xls')\n",
    "data_n=pd.read_excel('C:/Users/user/Desktop/psl/feature_normal.xls')\n",
    "\n",
    "G=data_g.drop(['target','type','m'],axis=1)\n",
    "L=data_l.drop(['target','type','m'],axis=1)\n",
    "N=data_n.drop(['target','type','m'],axis=1)\n",
    "\n",
    "GLN = pd.concat([G, L, N])\n",
    "\n",
    "print(G.shape)\n",
    "print(L.shape)\n",
    "print(N.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca_comp1    1.367664\n",
      "pca_comp2    0.208541\n",
      "pca_comp3   -0.070414\n",
      "dtype: float64\n",
      "(3,)\n",
      "[2.74903542 0.31987367 0.36005942]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import plotly.express as px\n",
    "import numpy.linalg as linalg\n",
    "\n",
    "pca=PCA(n_components=3)\n",
    "G_pca=pca.fit(G)\n",
    "L_pca=pca.fit(L)\n",
    "N_pca=pca.fit(N)\n",
    "\n",
    "G = G_pca.transform(G)\n",
    "L = L_pca.transform(L)\n",
    "N = N_pca.transform(N)\n",
    "\n",
    "columns = ['pca_comp1', 'pca_comp2', 'pca_comp3']\n",
    "\n",
    "G = pd.DataFrame(G, columns = columns)\n",
    "L = pd.DataFrame(L, columns = columns)\n",
    "N = pd.DataFrame(N, columns = columns)\n",
    "\n",
    "G_mean=G.mean(0)\n",
    "L_mean=L.mean(0)\n",
    "N_mean=N.mean(0)\n",
    "G_std=np.array(np.std(G))\n",
    "L_std=np.array(np.std(L))\n",
    "N_std=np.array(np.std(N))\n",
    "print(G_mean)\n",
    "print(G_mean.shape)\n",
    "print(G_std)\n",
    "print(G_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pca_comp1  pca_comp2  pca_comp3\n",
      "pca_comp1   7.568007  -0.299811   0.310439\n",
      "pca_comp2  -0.299811   0.102466  -0.034034\n",
      "pca_comp3   0.310439  -0.034034   0.129828\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "G_cov=G.cov()\n",
    "L_cov=L.cov()\n",
    "N_cov=N.cov()\n",
    "print(G_cov)\n",
    "print(G_cov.shape)\n",
    "# G_V, G_W =np.linalg.eig(np.cov(G.values.T))\n",
    "# L_V, L_W =np.linalg.eig(np.cov(L.values.T))\n",
    "# N_V, N_W =np.linalg.eig(np.cov(N.values.T))\n",
    "\n",
    "# print(\"Eigen value: \",G_V)\n",
    "# print(\"Eigen vector: \",G_W)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다변수에 위에꺼 넣기\n",
    "# 지락확률분포 하나 선간확률분포 하나 정상확률분포 하나\n",
    "from scipy.stats import multivariate_normal\n",
    "g_pdf=multivariate_normal(G_mean,G_cov,allow_singular=True)\n",
    "n_pdf=multivariate_normal(N_mean,N_cov,allow_singular=True)\n",
    "l_pdf=multivariate_normal(L_mean,L_cov,allow_singular=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but PCA was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 48 features, but PCA is expecting 3 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [96], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m data_te\u001b[38;5;241m=\u001b[39mtest\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_te\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 5\u001b[0m te_g \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mG_pca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_te\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[0;32m      6\u001b[0m te_n \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(N_pca\u001b[38;5;241m.\u001b[39mtransform(data_te), columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[0;32m      7\u001b[0m te_l \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(L_pca\u001b[38;5;241m.\u001b[39mtransform(data_te), columns\u001b[38;5;241m=\u001b[39mcolumns)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\decomposition\\_base.py:117\u001b[0m, in \u001b[0;36m_BasePCA.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m\"\"\"Apply dimensionality reduction to X.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[39mX is projected on the first principal components previously extracted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39m    is the number of samples and `n_components` is the number of the components.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 117\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     X \u001b[39m=\u001b[39m X \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    587\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 48 features, but PCA is expecting 3 features as input."
     ]
    }
   ],
   "source": [
    "test=pd.read_excel('C:/Users/user/Desktop/psl/fault_feature_seongan.xls')\n",
    "data_te=test.drop(['target','type','m'],axis=1)\n",
    "print(data_te.shape)\n",
    "\n",
    "te_g = G_pca.transform(data_te)\n",
    "te_n = N_pca.transform(data_te)\n",
    "te_l = L_pca.transform(data_te)\n",
    "\n",
    "te_g = pd.DataFrame(te_g, columns=columns)\n",
    "te_n = pd.DataFrame(te_n, columns=columns)\n",
    "te_l = pd.DataFrame(te_l, columns=columns)\n",
    "\n",
    "prob_g = g_pdf.pdf(data_te) # g_pdf.pdf(48차원 데이터) -> 해당 데이터의 지락고장 확률이 나온다.\n",
    "prob_n = n_pdf.pdf(data_te)\n",
    "prob_l = l_pdf.pdf(data_te)\n",
    "print(prob_g)\n",
    "print(prob_n)\n",
    "print(prob_l)\n",
    "print(prob_g.shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
